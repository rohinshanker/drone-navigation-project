<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Drone Navigation Through Constrained Gate Environments | Team 44</title>
  <meta name="description" content="EECS/ME C106A/206A Final Project (Fall 2025). Team 44 built an autonomous drone pipeline for navigating through constrained gate environments using receding-horizon LQR and ArUco-based vision." />
  <link rel="icon" href="./assets/img/favicon.svg" type="image/svg+xml" />
  <link rel="stylesheet" href="./assets/css/styles.css" />
</head>

<body>

  <header class="site-header" id="top">
    <div class="container header-inner">
      <div class="brand">
        <a href="#top" class="brand-link" aria-label="Home">
          <span class="brand-mark">44</span>
          <span class="brand-text">
            <span class="brand-title">Drone Gate Navigation</span>
            <span class="brand-subtitle">EECS/ME C106A/206A ¬∑ Fall 2025</span>
          </span>
        </a>
      </div>

      <button class="nav-toggle" type="button" aria-label="Open navigation" aria-expanded="false" aria-controls="site-nav">
        <span class="nav-toggle-bars" aria-hidden="true"></span>
      </button>

      <nav class="site-nav" id="site-nav" aria-label="Primary">
        <a href="#overview">Overview</a>
        <a href="#demo">Demo</a>
        <a href="#system">System</a>
        <a href="#hardware">Hardware</a>
        <a href="#software">Software</a>
        <a href="#operation">Operation</a>
        <a href="#vision">Vision</a>
        <a href="#impact">Real-world impact</a>
        <a href="#team">Team</a>
      </nav>
    </div>
  </header>

  <main id="main">
    <!-- ========================= -->
    <!-- HERO / OVERVIEW           -->
    <!-- ========================= -->
    <section id="overview" class="section hero">
      <div class="container hero-grid">
        <div class="hero-copy">
          <p class="kicker">Team 44 ¬∑ Final Project Website</p>
          <h1>Drone Navigation Through Constrained Gate Environments</h1>

          <p class="lead">
            We built a modular autonomy pipeline that uses an FPV camera + ArUco marker detection to localize a gate,
            then plans and executes a path using a discrete-time receding-horizon LQR controller. We validated the
            approach in MuJoCo (propeller-thrust actuation) and adapted it to DJI Tello hardware (SDK position/yaw commands).
          </p>

          <div class="hero-actions">
            <a class="btn primary" href="#demo">Watch the demo</a>
            <a class="btn" href="#system">Overview &amp; Design</a>
            <a class="btn subtle" href="./assets/docs/EECS%20C106A%20Final%20Project%20-%20Group%2044%20-%20Google%20Slides.pdf" target="_blank" rel="noreferrer">
              View slides (PDF)
            </a>
          </div>

          <div class="callouts">
            <div class="callout">
              <h3>Sensing</h3>
              <p>FPV camera + OpenCV ArUco detection for gate pose estimation.</p>
            </div>
            <div class="callout">
              <h3>Planning &amp; Control</h3>
              <p>Receding-horizon LQR with tunable horizon length and Q/R/P weights.</p>
            </div>
            <div class="callout">
              <h3>Actuation</h3>
              <p>MuJoCo: propeller thrusts. DJI Tello: high-level translation + yaw commands.</p>
            </div>
          </div>

        </div>

        <div class="hero-media">
          <figure class="media-card full">
            <a href="./assets/docs/EECS%20C106A%20Final%20Project%20-%20Group%2044%20-%20Google%20Slides.pdf" target="_blank" rel="noreferrer">
              <img src="./assets/img/slides/slide_01.png" alt="Title slide: Drone Navigation Through Constrained Gate Environments" loading="lazy" />
            </a>
            <figcaption>Click to open the full presentation (PDF).</figcaption>
          </figure>
        </div>
      </div>
    </section>

    <!-- ========================= -->
    <!-- DEMO                      -->
    <!-- ========================= -->
    <section id="demo" class="section alt">
      <div class="container">
        <header class="section-header style-a">
          <h2>Demo</h2>
          <p class="muted">
            Video demonstration of our drone flying through the gates we made. 
          </p>
        </header>

        <div class="video-grid">
          <div class="video-card">
            <div class="video-embed" aria-label="Demo video placeholder">
              <video controls playsinline preload="metadata" aria-label="Drone gate navigation demo">
                <source src="./assets/videos/livedemo.mp4" type="video/mp4" />
                Your browser does not support the video tag.
              </video>
            </div>
            <p class="muted small">
              Live demo: DJI Tello flying through gate using onboard FPV camera + ArUco-based perception + receding-horizon LQR control.
            </p>
          </div>

          <figure class="media-card">
            <a href="./assets/videos/livedemo.mp4" target="_blank" rel="noreferrer">
              <img src="./assets/img/slides/slide_29.png" alt="Photo of the physical gate setup used for the demo" loading="lazy" />
            </a>
            <figcaption>Click here to open video in new tab.</figcaption>
          </figure>
        </div>
      
    </section>

    <!-- ========================= -->
    <!-- PROBLEM / GOALS           -->
    <!-- ========================= -->
    <section id="problem" class="section">
      <div class="container">
        <header class="section-header style-a">
          <h2>Problem statement &amp; goals</h2>
        </header>

        <div class="two-col">
          <div>
            <p>
              The goal of this project is to build a modular autonomy pipeline for vision-based drone navigation that uses an 
              FPV camera and ArUco marker detection to localize a gate and a receding-horizon LQR controller to plan and 
              execute a trajectory. The system is validated in MuJoCo simulation software and then adapted to be used with a 
              DJI Tello drone.
            </p>
            <p class="muted">
              This project is interesting because it integrates perception, planning, and control into a complete autonomous 
              system. Key challenges include reliable monocular visual localization, designing a stable receding-horizon 
              controller under actuation limits, and transferring the approach from simulation to real hardware.

            </p>
            <p class="muted">
              The methods developed are fundamental to autonomous aerial robotics and are applicable to tasks 
              such as GPS-denied navigation, inspection, search and rescue, indoor logistics, and path planning.
            </p>
          </div>

          <figure class="media-card">
            <img src="./assets/img/slides/slide_03.png" alt="Slide describing initial goals and pipeline components (perception, localization, trajectory planning)" loading="lazy" />
            <figcaption>High-level system goals.</figcaption>
          </figure>
        </div>
      </div>
    </section>

    <!-- ========================= -->
    <!-- SYSTEM OVERVIEW           -->
    <!-- ========================= -->
    <section id="system" class="section alt">
      <div class="container">
        <header class="section-header style-a">
          <h2>System Overview &amp; Design</h2>
          <p class="muted">
            How the perception, planning, and control pieces fit together, and the design decisions behind them.
          </p>
        </header>

        <div class="two-col">
          <div class="stack">
            <p class="muted">
               The system must autonomously detect and localize a gate using onboard vision, plan a trajectory to the target, and execute the motion in a closed loop while remaining stable and responsive. It must operate in real time, be robust to perception noise, and support both simulation and real hardware.
            </p>
            <p class="muted">
               We implemented a modular pipeline consisting of visual perception, planning, and control. An FPV camera detects ArUco markers to estimate the gate pose, which defines a target state. A discrete-time receding-horizon LQR controller computes control actions to reach the target. The design was validated in MuJoCo simulator with propeller-level actuation and adapted to a DJI Tello using SDK-level position and yaw commands.
            </p>
            <p class="muted">
              ArUco markers were chosen for reliable and computationally efficient obstacle localization instead of training a learning-based vision model. This decision was driven by time constraints and the need for consistent, repeatable performance. 
            </p>
            <p class="muted">
              A receding-horizon optimal control approach (MPC/LQR) was selected to provide closed-loop feedback and predictive behavior, rather than using a simple PID controller or open-loop path planning. This choice improves stability and robustness to disturbances and modeling errors, at the cost of increased computational complexity compared to simpler controllers.
            </p>
            <p class="muted">
              The design produces a stable, efficient, and modular system that can run in real time on limited hardware. While marker-based perception restricts operation in unstructured environments, the approach is well-suited for controlled settings and provides a clear path toward more advanced perception and control techniques.  
            </p>
          </div>

          <div class="stack">
            <figure class="media-card">
              <img src="./assets/img/slides/slide_15.png" alt="Autonomous pipeline flowchart" loading="lazy" />
              <figcaption>Pipeline block diagram used in our final presentation.</figcaption>
            </figure>
            <div class="card">
              <h3>Repository</h3>
              <p class="muted">
                <a href="https://github.com/alexmunicio/mujoco_drone_simulator" target="_blank" rel="noreferrer">mujoco_drone_simulator</a> ‚Äî MuJoCo drone simulator codebase.
              </p>
            </div>
            <div class="card">
              <h3>Key assumptions</h3>
              <ul class="muted">
                <li>Simulation: ground-truth state available for state estimation.</li>
                <li>Hardware testing: rely on the DJI Tello SDK's onboard state estimate.</li>
                <li>Initialization: takeoff begins where the ArUco tags are in view to bootstrap perception.</li>
              </ul>
            </div>
          </div>
        </div>

        <details class="details">
          <summary><strong>Appendix:</strong> Experimental conditions &amp; simplifications (from slides)</summary>
          <div class="details-inner">
            <img src="./assets/img/slides/slide_16.png" alt="Slide listing experimental conditions and simplifications" loading="lazy" />
          </div>
        </details>
      </div>
    </section>

    <!-- ========================= -->
    <!-- HARDWARE                  -->
    <!-- ========================= -->
    <section id="hardware" class="section">
      <div class="container">
        <header class="section-header style-a">
          <h2>Implementation: Hardware Selection &amp; Integration</h2>
          <p class="muted">
            We explored two drone platforms. The primary challenge was achieving autonomous control access that matched our controller output.
          </p>
        </header>

        <div class="feature-rows">
          <div class="feature">
            <figure class="feature-media">
              <img src="./assets/img/slides/slide_24.png" alt="Slide about Drone 1 JY08 Pro and Wireshark interception attempt" loading="lazy" />
            </figure>
            <div class="feature-body">
              <h3>Drone 1: JY08 Pro (attempt)</h3>
              <p>
                This drone was controlled through Wi-Fi commands sent from a mobile app. We attempted to intercept and replicate command packets
                (WireShark), and considered sending commands via an Android emulator, but the takeoff sequence could not be reliably emulated.
              </p>
            </div>
          </div>

          <div class="feature">
            <figure class="feature-media">
              <img src="./assets/img/slides/slide_25.png" alt="Slide about DJI Tello SDK limitations and command interface" loading="lazy" />
            </figure>
            <div class="feature-body">
              <h3>Drone 2: DJI Tello (final hardware)</h3>
              <p>
                We chose DJI Tello because the official SDK allows autonomous control, but it provides only high-level commands (e.g., ‚Äúmove forward one meter‚Äù),
                not low-level propeller thrust control. We therefore adapted our planner/controller output to the SDK‚Äôs command interface.
              </p>
            </div>
          </div>
        </div>


        <div class="stack">
          <div class="parts-grid">
            <div class="part-card">
              <div class="icon-placeholder">üì∑</div>
              <div>
                <h4>Video Camera Stream</h4>
                <p class="muted">[Add your camera/FPV streaming setup and wiring here.]</p>
              </div>
            </div>
            <div class="part-card">
              <div class="icon-placeholder">üì°</div>
              <div>
                <h4>Command Broadcasting</h4>
                <p class="muted">[Add your networking/command broadcast setup here.]</p>
              </div>
            </div>
          </div>
        </div>

        <details class="details">
          <summary><strong>Adapting the controller to Tello‚Äôs SDK</strong></summary>
          <div class="details-inner">
            <div class="gallery">
              <figure class="media-card">
                <img src="./assets/img/slides/slide_26.png" alt="Adapting our controller workaround slide" loading="lazy" />
                <figcaption>Workaround strategy.</figcaption>
              </figure>
              <figure class="media-card">
                <img src="./assets/img/slides/slide_27.png" alt="Adjusting cost function weights for Tello hardware slide" loading="lazy" />
                <figcaption>Penalize roll/pitch to favor straight translational motion.</figcaption>
              </figure>
              <figure class="media-card">
                <img src="./assets/img/slides/slide_28.png" alt="Adjusted hardware QRP weights plot slide" loading="lazy" />
                <figcaption>Hardware-oriented Q/R/P tuning (example).</figcaption>
              </figure>
            </div>

            <p class="muted small">
              <span class="todo">TODO ‚Äî describe your discretization method: how you convert a continuous trajectory into a sequence of Tello commands.</span>
            </p>
          </div>
        </details>
      </div>
    </section>


    <!-- ========================= -->
    <!-- SOFTWARE                 -->
    <!-- ========================= -->

    <section id="software" class="section gradient">
      <div class="container">
        <header class="section-header style-a">
          <h2>Implementation: Full-Stack Technical Rundown</h2>
          <p class="muted">Full technical walk through of all the parts and how they fit together.</p>
        </header>


        <div class="tab-card inline" id="hardware-overview-card">
          <div class="tab-title" style="font-size:22px;">Hardware Overview</div>
          <div class="tab-panel active">
            <div class="two-col">
              <div class="stack">
                <h3>Hardware</h3>
                <div class="cards-grid" style="grid-template-columns: repeat(1, 1fr); margin-top: 0;">
                  <div class="card">
                    <h3>DJI Tello Drone</h3>
                    <p>A lightweight quadrotor used as the aerial platform. The drone provided:</p>
                    <div class="cards-grid" style="grid-template-columns: repeat(2, 1fr); margin-top: 10px;">
                      <div class="card"><p class="muted">An onboard forward-facing FPV camera</p></div>
                      <div class="card"><p class="muted">Wireless communication over Wi-Fi</p></div>
                      <div class="card"><p class="muted">High-level motion commands (translations and yaw)</p></div>
                      <div class="card"><p class="muted">Internal low-level stabilization (attitude and motor control)</p></div>
                    </div>
                  </div>
                  <div class="card">
                    <h3>Obstacle Course (Rectangular Hoops Made out of PVC Pipes)</h3>
                    <p class="muted">Each obstacle was a rectangular gate with <strong>ArUco tags mounted on its four corners</strong>, allowing reliable visual detection and geometric pose estimation.</p>
                  </div>
                  <div class="card">
                    <h3>Ground Computer (Laptop)</h3>
                    <ul class="muted">
                      <li>Receive the live video stream</li>
                      <li>Run computer vision and state estimation</li>
                      <li>Solve the MPC/LQR optimization problem</li>
                      <li>Send motion commands back to the drone</li>
                    </ul>
                  </div>
                </div>
              </div>
              <div class="stack">
                <h3>Software &amp; Libraries</h3>
                <div class="cards-grid" style="grid-template-columns: 1fr; margin-top: 0;">
                  <div class="card">
                    <h3>DJI Tello SDK</h3>
                    <ul class="muted">
                      <li>Sending flight commands (<code>takeoff</code>, <code>land</code>, translations, yaw)</li>
                      <li>Receiving the FPV video stream over Wi-Fi</li>
                    </ul>
                  </div>
                  <div class="card">
                    <h3>Control Stack</h3>
                    <ul class="muted">
                      <li>OpenCV2 for ArUco detection</li>
                      <li>Casadi Optimization Library</li>
                      <li>C++ IPOPT optimization algorithm (interior point method)</li>
                      <li>MPC controller</li>
                      <li>Custom trajectory post-processing and command generation logic</li>
                    </ul>
                  </div>
                  <div class="card">
                    <h3>Software Architecture and Implementation Details</h3>
                    <p class="muted">The software was structured as a <strong>checkpoint-based autonomy pipeline</strong>, where each obstacle (including takeoff and landing) was treated as a discrete goal state.</p>
                    <p class="muted">The system continuously cycles through the following stages:</p>
                    <ol class="muted">
                      <li>State estimation</li>
                      <li>Checkpoint evaluation</li>
                      <li>Perception (ArUco detection)</li>
                      <li>Trajectory planning (MPC/LQR)</li>
                      <li>Command execution</li>
                      <li>Transition to the next checkpoint</li>
                    </ol>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>

        <div class="tab-card side" id="software-modules-tabs">
          <div class="tab-title" style="font-size:22px;">Key Software Modules</div>
          <div class="tab-inner">
            <div class="tab-list" role="tablist" aria-label="Software modules tabs">
              <button type="button" role="tab" aria-selected="true" data-tab="mod-state">State Estimation</button>
              <button type="button" role="tab" aria-selected="false" data-tab="mod-perception">Perception</button>
              <button type="button" role="tab" aria-selected="false" data-tab="mod-mpc">MPC / LQR</button>
              <button type="button" role="tab" aria-selected="false" data-tab="mod-cost">Cost Function</button>
              <button type="button" role="tab" aria-selected="false" data-tab="mod-trajectory">Trajectory Post-Processing</button>
            </div>
            <div class="tab-panel active" id="tab-mod-state" role="tabpanel">
              <h3>State Estimation</h3>
              <ul class="muted">
                <li>Last known commanded motion</li>
                <li>Camera-based pose estimation relative to the obstacle</li>
                <li>Relative positioning to detected obstacles</li>
                <li>Assumptions about motion execution accuracy</li>
              </ul>
            </div>
            <div class="tab-panel" id="tab-mod-perception" role="tabpanel">
              <h3>Perception: ArUco-Based Obstacle Localization</h3>
              <p class="muted">The FPV video stream was processed using OpenCV</p>
              <p class="muted">Steps:</p>
              <ol class="muted">
                <li>Detect the four ArUco tags on an obstacle</li>
                <li>Infer the 3D pose of each tag relative to the camera</li>
                <li>Compute the <strong>center point of the rectangular gate</strong></li>
              </ol>
              <p class="muted">This center point became the <strong>next checkpoint target</strong> for the controller.</p>
            </div>
            <div class="tab-panel" id="tab-mod-mpc" role="tabpanel">
              <h3>Model Predictive Control with Constrained LQR Cost</h3>
              <p class="muted">Originally in simulation, the controller:</p>
              <ul class="muted">
                <li>Output continuous thrust and torque commands</li>
                <li>Used a <strong>short receding horizon</strong> for real-time control</li>
              </ul>
              <h4>Hardware-Driven Modifications (SDK limits)</h4>
              <ul class="muted">
                <li>Translational commands ‚â• <strong>10 cm</strong></li>
                <li>Rotational commands ‚â• <strong>10¬∞</strong></li>
                <li>Commands executed slowly with pauses, stabilized onboard</li>
              </ul>
              <p class="muted">As a result, the MPC horizon was <strong>lengthened</strong>, allowed more compute time, and issued fewer commands to reduce drift and uncertainty.</p>
            </div>
            <div class="tab-panel" id="tab-mod-cost" role="tabpanel">
              <h3>Cost Function Adjustments</h3>
              <p class="muted">To ensure feasible real-world flight:</p>
              <ul class="muted">
                <li><strong>Roll and pitch states</strong> heavily penalized</li>
                <li><strong>Torques about x/y</strong> heavily penalized</li>
              </ul>
              <p class="muted">Encouraged:</p>
              <ul class="muted">
                <li>Straight-line translational motion</li>
                <li>Yaw-based reorientation</li>
                <li>Minimal aggressive maneuvering</li>
              </ul>
            </div>
            <div class="tab-panel" id="tab-mod-trajectory" role="tabpanel">
              <h3>Trajectory Post-Processing</h3>
              <p class="muted">Instead of directly applying control inputs:</p>
              <ol class="muted">
                <li>Compute the optimal MPC trajectory over the horizon</li>
                <li>Decompose into <strong>three sequential commands</strong>:
                  <ul>
                    <li>Vertical translation</li>
                    <li>Yaw rotation</li>
                    <li>Forward/backward translation</li>
                  </ul>
                </li>
                <li>Discretize each to satisfy SDK constraints</li>
                <li>Send commands wirelessly to the drone</li>
              </ol>
            </div>
          </div>
        </div>

      </div>
    </section>

    <!-- ========================= -->
    <!-- ========================= -->
    <!-- OPERATION                  -->
    <!-- ========================= -->
    <section id="operation" class="section alt">
      <div class="container">
        <header class="section-header style-a">
          <h2>Complete System Operation</h2>
          <p class="muted">Step-by-Step Autonomous Pipeline. Hover over nodes for details.</p>
        </header>
      </div>
    </section>

    <!-- SIMULATOR                 -->
    <!-- ========================= -->
    <section id="sim" class="section alt">
      <div class="container">
        <header class="section-header style-a">
          <h2>Simulation in MuJoCo</h2>
          <p class="muted">
            We used MuJoCo to iterate quickly on dynamics, controller tuning, and perception assumptions before hardware testing.
          </p>
        </header>

        <div class="two-col">
          <div>
            <h3>What we modeled</h3>
            <ul>
              <li>Drone rigid-body dynamics with symmetric inertia tensor</li>
              <li>Limited thrust and torque range</li>
              <li>Propeller-level actuation (thrust per motor)</li>
              <li>Gates marked with ArUco tags</li>
              <li>Simulated FPV camera</li>
            </ul>

            <p class="muted small">
              <span class="todo">TODO ‚Äî add the MuJoCo XML link/path and a brief ‚Äúhow to run sim‚Äù section with commands.</span>
            </p>
          </div>

          <figure class="media-card">
            <video controls playsinline preload="metadata">
              <source src="./assets/videos/mujocosimulator.mp4" type="video/mp4" />
              Your browser does not support the video tag.
            </video>
            <figcaption>MuJoCo simulator run (gates with ArUco tags).</figcaption>
          </figure>
        </div>
      </div>
    </section>

    <!-- ========================= -->
    <!-- VISION                    -->
    <!-- ========================= -->
    <section id="vision" class="section">
      <div class="container">
        <header class="section-header style-a">
          <h2>Computer vision &amp; mapping</h2>
          <p class="muted">
            We estimate the gate pose in the world frame from the FPV camera feed using OpenCV ArUco detection + a PnP solver.
          </p>
        </header>

        <div class="two-col">
          <div>
            <h3>Approach</h3>
            <ol>
              <li>Detect ArUco corners in the camera image</li>
              <li>Solve PnP to obtain the camera-to-tag transform</li>
              <li>Compute the gate center in the camera frame</li>
              <li>Transform to the world frame (using known frame transforms)</li>
            </ol>

            <div class="checklist">
              <h3>What to add for the final write-up</h3>
              <ul>
                <li><span class="todo">TODO ‚Äî mention the ArUco dictionary + marker size you used</span></li>
                <li><span class="todo">TODO ‚Äî describe camera calibration (intrinsics) and how you obtained them</span></li>
                <li><span class="todo">TODO ‚Äî include a screenshot of detections + estimated pose axes overlay</span></li>
              </ul>
            </div>
          </div>

          <figure class="media-card">
            <img src="./assets/img/slides/slide_21.png" alt="Diagram showing coordinate frames and transforms for mapping the ArUco tag to world frame" loading="lazy" />
            <figcaption>Frame-transform diagram used for gate localization.</figcaption>
          </figure>
        </div>
      </div>
    </section>

          <figcaption><span class="todo">TODO ‚Äî add a montage: detection overlay + planned path + execution.</span></figcaption>
        </figure>
      </div>
    </section>

    <!-- ========================= -->
    <!-- REAL-WORLD IMPACT         -->
    <!-- ========================= -->
    <section id="impact" class="section">
      <div class="container">
        <header class="section-header style-a">
          <h2>Real-world extensions &amp; societal impact</h2>
          <p class="muted">
            The course asks for a section describing how your project could extend to the real world and what implications the technology might have in society.
          </p>
        </header>

        <div class="two-col">
          <div>
            <h3>Potential real-world extensions</h3>
            <ul>
              <li><strong>Infrastructure inspection:</strong> constrained navigation through trusses, under bridges, or inside industrial sites</li>
              <li><strong>Search &amp; rescue:</strong> passing through openings in damaged structures</li>
              <li><strong>Warehouse autonomy:</strong> navigation through aisles/frames with visual landmarks</li>
              <li><strong>Drone racing R&amp;D:</strong> stepping stone toward fully vision-based racing gates and higher-performance control</li>
            </ul>

            <h3>Societal considerations</h3>
            <ul>
              <li><strong>Safety:</strong> failure modes in cluttered spaces can cause injury/property damage</li>
              <li><strong>Privacy:</strong> camera-based navigation raises surveillance concerns</li>
              <li><strong>Misuse:</strong> autonomy in constrained spaces can be repurposed for harmful applications</li>
              <li><strong>Equity:</strong> who benefits from deployment (public good vs private gain)</li>
            </ul>
          </div>

          <div class="card">
            <h3 class="tight">Write-up prompts (fill these in)</h3>
            <ol class="tight">
              <li><span class="todo">TODO ‚Äî Where would this system be deployed, and what is the value?</span></li>
              <li><span class="todo">TODO ‚Äî What technical changes are required to deploy responsibly (robust perception, SLAM, redundancy)?</span></li>
              <li><span class="todo">TODO ‚Äî What safety policies would you enforce (geofencing, speed limits, human-in-the-loop)?</span></li>
            </ol>
          </div>
        </div>
      </div>
    </section>

    <!-- ========================= -->
    <!-- TEAM                      -->
    <!-- ========================= -->
    <section id="team" class="section alt">
      <div class="container">
        <header class="section-header style-a">
          <h2>Team</h2>
          <p class="muted">
            Alejandro Municio ¬∑ Ben Finch ¬∑ Michael Howo ¬∑ Rohin Shanker
          </p>
        </header>

        <div class="cards-grid">
          <div class="card">
            <h3>Alejandro Municio</h3>
            <p class="muted"><a href="https://www.linkedin.com/in/alejandro-municio-aerospace/" target="_blank" rel="noreferrer"><svg class="icon-linkedin" viewBox="0 0 448 512" aria-hidden="true" focusable="false"><path d="M100.28 448H7.4V148.9h92.88zm-46.44-339C24 109 0 85 0 54.9A54.9 54.9 0 0 1 54.13 0a54.88 54.88 0 1 1-.29 109zm394.16 339h-92.68V302.4c0-34.7-12.45-58.4-43.55-58.4-23.74 0-37.88 16-44.1 31.4-2.26 5.5-2.82 13.1-2.82 20.8V448h-92.78s1.22-251.1 0-277.1h92.78v39.3c-.18.3-.43.6-.6.9h.6v-.9c12.34-19 34.35-46.1 83.6-46.1 61 0 106.68 39.9 106.68 125.5z"/></svg>LinkedIn</a></p>
          </div>
          <div class="card">
            <h3>Ben Finch</h3>
            <p class="muted"><a href="https://www.linkedin.com/in/ben--finch/" target="_blank" rel="noreferrer"><svg class="icon-linkedin" viewBox="0 0 448 512" aria-hidden="true" focusable="false"><path d="M100.28 448H7.4V148.9h92.88zm-46.44-339C24 109 0 85 0 54.9A54.9 54.9 0 0 1 54.13 0a54.88 54.88 0 1 1-.29 109zm394.16 339h-92.68V302.4c0-34.7-12.45-58.4-43.55-58.4-23.74 0-37.88 16-44.1 31.4-2.26 5.5-2.82 13.1-2.82 20.8V448h-92.78s1.22-251.1 0-277.1h92.78v39.3c-.18.3-.43.6-.6.9h.6v-.9c12.34-19 34.35-46.1 83.6-46.1 61 0 106.68 39.9 106.68 125.5z"/></svg>LinkedIn</a></p>
          </div>
          <div class="card">
            <h3>Michael Howo</h3>
            <p class="muted"><a href="https://www.linkedin.com/in/michaelhowo/" target="_blank" rel="noreferrer"><svg class="icon-linkedin" viewBox="0 0 448 512" aria-hidden="true" focusable="false"><path d="M100.28 448H7.4V148.9h92.88zm-46.44-339C24 109 0 85 0 54.9A54.9 54.9 0 0 1 54.13 0a54.88 54.88 0 1 1-.29 109zm394.16 339h-92.68V302.4c0-34.7-12.45-58.4-43.55-58.4-23.74 0-37.88 16-44.1 31.4-2.26 5.5-2.82 13.1-2.82 20.8V448h-92.78s1.22-251.1 0-277.1h92.78v39.3c-.18.3-.43.6-.6.9h.6v-.9c12.34-19 34.35-46.1 83.6-46.1 61 0 106.68 39.9 106.68 125.5z"/></svg>LinkedIn</a></p>
          </div>
          <div class="card">
            <h3>Rohin Shanker</h3>
            <p class="muted"><a href="https://www.linkedin.com/in/rohin-shanker/" target="_blank" rel="noreferrer"><svg class="icon-linkedin" viewBox="0 0 448 512" aria-hidden="true" focusable="false"><path d="M100.28 448H7.4V148.9h92.88zm-46.44-339C24 109 0 85 0 54.9A54.9 54.9 0 0 1 54.13 0a54.88 54.88 0 1 1-.29 109zm394.16 339h-92.68V302.4c0-34.7-12.45-58.4-43.55-58.4-23.74 0-37.88 16-44.1 31.4-2.26 5.5-2.82 13.1-2.82 20.8V448h-92.78s1.22-251.1 0-277.1h92.78v39.3c-.18.3-.43.6-.6.9h.6v-.9c12.34-19 34.35-46.1 83.6-46.1 61 0 106.68 39.9 106.68 125.5z"/></svg>LinkedIn</a></p>
          </div>
        </div>

        
      </div>
    </section>

    <footer class="site-footer">
      <div class="container footer-inner">
        <p class="muted small">
          Team 44 ¬∑ EECS/ME C106A/206A (Fall 2025).
        </p>
        <a class="back-to-top" href="#top">Back to top</a>
      </div>
    </footer>
  </main>

  <div id="lightbox" aria-hidden="true">
    <button id="lightbox-close" class="lightbox-close" aria-label="Close image">√ó</button>
    <img id="lightbox-img" alt="" />
  </div>

  <script src="./assets/js/main.js"></script>
</body>
</html>
