<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Drone Navigation Through Constrained Gate Environments | Team 44</title>
  <meta name="description" content="EECS/ME C106A/206A Final Project (Fall 2025). Team 44 built an autonomous drone pipeline for navigating through constrained gate environments using receding-horizon LQR and ArUco-based vision." />
  <link rel="icon" href="./assets/img/favicon.svg" type="image/svg+xml" />
  <link rel="stylesheet" href="./assets/css/styles.css" />
  <style id="flowchart-styles">
    :root{
      --flow-bg: #0f1216;
      --flow-panel: #10151c;
      --flow-text: #eef2f7;
      --flow-muted: #a7b0bf;
      --flow-border: rgba(255,255,255,0.12);
      --flow-glow: rgba(88,166,255,0.35);
      --flow-shadow: rgba(0,0,0,0.35);
    }
    .flow-wrapper{
      width: min(1200px, 100%);
      margin: 0 auto;
    }
    .flowchart{
      position: relative;
      background: radial-gradient(900px 500px at 20% 0%, rgba(88,166,255,0.08), transparent 60%),
                  radial-gradient(700px 400px at 90% 10%, rgba(43,212,197,0.08), transparent 60%),
                  var(--flow-bg);
      border: 1px solid var(--flow-border);
      border-radius: 18px;
      padding: 90px 36px 36px;
      box-shadow: 0 30px 60px var(--flow-shadow);
      overflow: visible;
      color: var(--flow-text);
    }
    .flowchart .nodes{
      display: grid;
      grid-template-columns: repeat(6, minmax(0, 1fr));
      grid-template-rows: auto auto;
      gap: 18px;
      align-items: center;
      position: relative;
      z-index: 2;
    }
    .flowchart .node{
      appearance: none;
      border: 1px solid var(--flow-border);
      background: linear-gradient(140deg, rgba(255,255,255,0.04), rgba(255,255,255,0.01));
      color: var(--flow-text);
      padding: 14px 12px;
      border-radius: 14px;
      font-size: 13px;
      font-weight: 650;
      letter-spacing: 0.01em;
      text-align: center;
      cursor: pointer;
      transition: transform 0.18s ease, box-shadow 0.18s ease, border-color 0.18s ease, background 0.18s ease;
      position: relative;
    }
    .flowchart .node span{
      display: block;
      font-size: 12px;
      color: var(--flow-muted);
      font-weight: 500;
      margin-top: 6px;
    }
    .flowchart .node:hover,
    .flowchart .node:focus-visible,
    .flowchart .node.active{
      transform: translateY(-2px);
      border-color: rgba(88,166,255,0.6);
      box-shadow: 0 10px 28px var(--flow-shadow), 0 0 0 6px rgba(88,166,255,0.08), 0 0 30px var(--flow-glow);
      background: linear-gradient(140deg, rgba(88,166,255,0.14), rgba(255,255,255,0.02));
      outline: none;
    }
    .flowchart .node:focus-visible{
      box-shadow: 0 0 0 3px rgba(88,166,255,0.8), 0 0 30px var(--flow-glow);
    }
    .flowchart .node[data-step="7"]{
      grid-column: 5 / span 2;
      grid-row: 2;
      justify-self: end;
    }
    .flowchart .connections{
      position: absolute;
      inset: 0;
      width: 100%;
      height: 100%;
      z-index: 1;
      pointer-events: none;
    }
    .flowchart .connections path{
      stroke: rgba(255,255,255,0.35);
      stroke-width: 2;
      fill: none;
    }
    .flowchart .popup{
      position: absolute;
      max-width: 360px;
      width: 100%;
      background: var(--flow-panel);
      border: 1px solid var(--flow-border);
      border-radius: 14px;
      padding: 14px;
      box-shadow: 0 26px 60px rgba(0,0,0,0.5);
      z-index: 5;
      opacity: 0;
      transform: translateY(6px);
      pointer-events: none;
      transition: opacity 0.18s ease, transform 0.18s ease;
    }
    .flowchart .popup.visible{
      opacity: 1;
      transform: translateY(0);
      pointer-events: auto;
    }
    .flowchart .popup .header{
      display: flex;
      align-items: center;
      gap: 10px;
      margin-bottom: 8px;
    }
    .flowchart .badge{
      background: #0a66c2;
      color: #fff;
      font-size: 12px;
      padding: 4px 8px;
      border-radius: 999px;
      font-weight: 700;
      letter-spacing: 0.03em;
    }
    .flowchart .popup h3{
      margin: 0;
      font-size: 16px;
    }
    .flowchart .popup ol,
    .flowchart .popup ul{
      margin: 8px 0 0 18px;
      padding: 0;
      color: var(--flow-muted);
      line-height: 1.45;
    }
    .flowchart .popup li{ margin-bottom: 6px; }
    .flowchart .popup code{
      background: rgba(255,255,255,0.08);
      border-radius: 6px;
      padding: 1px 6px;
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      font-size: 0.9em;
      color: var(--flow-text);
    }
    @media (max-width: 980px){
      .flowchart .nodes{
        grid-template-columns: repeat(3, minmax(0, 1fr));
        grid-template-rows: auto auto auto;
      }
      .flowchart .node[data-step="7"]{
        grid-column: 2 / span 2;
        justify-self: center;
      }
    }
    @media (max-width: 700px){
      .flowchart .nodes{
        grid-template-columns: 1fr 1fr;
      }
      .flowchart .node{
        font-size: 12px;
      }
    }
    @media (prefers-reduced-motion: reduce){
      .flowchart *{ transition: none !important; }
    }
  </style>
</head>

<body>

  <header class="site-header" id="top">
    <div class="container header-inner">
      <div class="brand">
        <a href="#top" class="brand-link" aria-label="Home">
          <span class="brand-mark">44</span>
          <span class="brand-text">
            <span class="brand-title">Drone Gate Navigation</span>
            <span class="brand-subtitle">EECS/ME C106A/206A ¬∑ Fall 2025</span>
          </span>
        </a>
      </div>

      <button class="nav-toggle" type="button" aria-label="Open navigation" aria-expanded="false" aria-controls="site-nav">
        <span class="nav-toggle-bars" aria-hidden="true"></span>
      </button>

      <nav class="site-nav" id="site-nav" aria-label="Primary">
        <a href="#overview">Overview</a>
        <a href="#demo">Demo</a>
        <a href="#system">System</a>
        <a href="#hardware">Hardware</a>
        <a href="#software">Software</a>
        <a href="#operation">Operation</a>
        <a href="#discussion">Discussion</a>
        <a href="#team">Team</a>
      </nav>
    </div>
  </header>

  <main id="main">
    <!-- ========================= -->
    <!-- HERO / OVERVIEW           -->
    <!-- ========================= -->
    <section id="overview" class="section hero">
      <div class="container hero-grid">
        <div class="hero-copy">
          <p class="kicker">Team 44 ¬∑ Final Project Website</p>
          <h1>Drone Navigation Through Constrained Gate Environments</h1>

          <p class="lead">
            We built a modular autonomy pipeline that uses an FPV camera + ArUco marker detection to localize a gate,
            then plans and executes a path using a discrete-time receding-horizon LQR controller. We validated the
            approach in MuJoCo (propeller-thrust actuation) and adapted it to DJI Tello hardware (SDK position/yaw commands).
          </p>

          <div class="hero-actions">
            <a class="btn primary" href="#demo">Watch the demo</a>
            <a class="btn" href="#system">Overview &amp; Design</a>
            <a class="btn subtle" href="./assets/docs/EECS%20C106A%20Final%20Project%20-%20Group%2044%20-%20Google%20Slides.pdf" target="_blank" rel="noreferrer">
              View slides (PDF)
            </a>
          </div>

          <div class="callouts">
            <div class="callout">
              <h3>Sensing</h3>
              <p>FPV camera + OpenCV ArUco detection for gate pose estimation.</p>
            </div>
            <div class="callout">
              <h3>Planning &amp; Control</h3>
              <p>Receding-horizon LQR with tunable horizon length and Q/R/P weights.</p>
            </div>
            <div class="callout">
              <h3>Actuation</h3>
              <p>MuJoCo: propeller thrusts. DJI Tello: high-level translation + yaw commands.</p>
            </div>
          </div>

        </div>

        <div class="hero-media">
          <figure class="media-card full">
            <a href="./assets/docs/EECS%20C106A%20Final%20Project%20-%20Group%2044%20-%20Google%20Slides.pdf" target="_blank" rel="noreferrer">
              <img src="./assets/img/slides/slide_01.png" alt="Title slide: Drone Navigation Through Constrained Gate Environments" loading="lazy" />
            </a>
            <figcaption>Click to open the full presentation (PDF).</figcaption>
          </figure>
        </div>
      </div>
    </section>

    <!-- ========================= -->
    <!-- DEMO                      -->
    <!-- ========================= -->
    <section id="demo" class="section alt">
      <div class="container">
        <header class="section-header style-a">
          <h2>Demo</h2>
          <p class="muted">
            Video demonstration of our drone flying through the gates we made. 
          </p>
        </header>

        <div class="video-grid">
          <div class="video-card">
            <div class="video-embed" aria-label="Demo video placeholder">
              <video controls playsinline preload="metadata" aria-label="Drone gate navigation demo">
                <source src="./assets/videos/mujocosimulator.mp4" type="video/mp4" />
                Your browser does not support the video tag.
              </video>
            </div>
            <p class="muted small">
              MujoCo simulation demo (showing gates with ArUco tags).
            </p>
          </div>

          <figure class="media-card">
            <a href="./assets/videos/livedemo.mp4" target="_blank" rel="noreferrer">
              <img src="./assets/img/slides/slide_29.png" alt="Photo of the physical gate setup used for the demo" loading="lazy" />
            </a>
            <figcaption>Click here to see live demo.</figcaption>
          </figure>
        </div>
      
    </section>

    <!-- ========================= -->
    <!-- PROBLEM / GOALS           -->
    <!-- ========================= -->
    <section id="problem" class="section">
      <div class="container">
        <header class="section-header style-a">
          <h2>Problem statement &amp; goals</h2>
        </header>

        <div class="two-col">
          <div>
            <p>
              The goal of this project is to build a modular autonomy pipeline for vision-based drone navigation that uses an 
              FPV camera and ArUco marker detection to localize a gate and a receding-horizon LQR controller to plan and 
              execute a trajectory. The system is validated in MuJoCo simulation software and then adapted to be used with a 
              DJI Tello drone.
            </p>
            <p class="muted">
              This project is interesting because it integrates perception, planning, and control into a complete autonomous 
              system. Key challenges include reliable monocular visual localization, designing a stable receding-horizon 
              controller under actuation limits, and transferring the approach from simulation to real hardware.

            </p>
            <p class="muted">
              The methods developed are fundamental to autonomous aerial robotics and are applicable to tasks 
              such as GPS-denied navigation, inspection, search and rescue, indoor logistics, and path planning.
            </p>
          </div>

          <figure class="media-card">
            <img src="./assets/img/slides/slide_03.png" alt="Slide describing initial goals and pipeline components (perception, localization, trajectory planning)" loading="lazy" />
            <figcaption>High-level system goals.</figcaption>
          </figure>
        </div>
      </div>
    </section>

    <!-- ========================= -->
    <!-- SYSTEM OVERVIEW           -->
    <!-- ========================= -->
    <section id="system" class="section alt">
      <div class="container">
        <header class="section-header style-a">
          <h2>System Overview &amp; Design</h2>
          <p class="muted">
            How the perception, planning, and control pieces fit together, and the design decisions behind them.
          </p>
        </header>

        <div class="two-col">
          <div class="stack">
            <p class="muted">
               The system must autonomously detect and localize a gate using onboard vision, plan a trajectory to the target, and execute the motion in a closed loop while remaining stable and responsive. It must operate in real time, be robust to perception noise, and support both simulation and real hardware.
            </p>
            <p class="muted">
               We implemented a modular pipeline consisting of visual perception, planning, and control. An FPV camera detects ArUco markers to estimate the gate pose, which defines a target state. A discrete-time receding-horizon LQR controller computes control actions to reach the target. The design was validated in MuJoCo simulator with propeller-level actuation and adapted to a DJI Tello using SDK-level position and yaw commands.
            </p>
            <p class="muted">
              ArUco markers were chosen for reliable and computationally efficient obstacle localization instead of training a learning-based vision model. This decision was driven by time constraints and the need for consistent, repeatable performance. 
            </p>
            <p class="muted">
              A receding-horizon optimal control approach (MPC/LQR) was selected to provide closed-loop feedback and predictive behavior, rather than using a simple PID controller or open-loop path planning. This choice improves stability and robustness to disturbances and modeling errors, at the cost of increased computational complexity compared to simpler controllers.
            </p>
            <p class="muted">
              The design produces a stable, efficient, and modular system that can run in real time on limited hardware. While marker-based perception restricts operation in unstructured environments, the approach is well-suited for controlled settings and provides a clear path toward more advanced perception and control techniques.  
            </p>
          </div>

          <div class="stack">
            <figure class="media-card">
              <img src="./assets/img/slides/slide_15.png" alt="Autonomous pipeline flowchart" loading="lazy" />
              <figcaption>Pipeline block diagram used in our final presentation.</figcaption>
            </figure>
            <div class="card">
              <h3>Repository</h3>
              <p class="muted">
                <a href="https://github.com/alexmunicio/mujoco_drone_simulator" target="_blank" rel="noreferrer">GitHub Repository</a> for our MuJoCo drone simulator codebase.
              </p>
            </div>
            <div class="card">
              <h3>Key assumptions</h3>
              <ul class="muted">
                <li>Simulation: ground-truth state available for state estimation.</li>
                <li>Hardware testing: rely on the DJI Tello SDK's onboard state estimate.</li>
                <li>Initialization: takeoff begins where the ArUco tags are in view to bootstrap perception.</li>
              </ul>
            </div>
          </div>
        </div>

        <details class="details">
          <summary><strong>Appendix:</strong> Experimental conditions &amp; simplifications (from slides)</summary>
          <div class="details-inner">
            <img src="./assets/img/slides/slide_16.png" alt="Slide listing experimental conditions and simplifications" loading="lazy" />
          </div>
        </details>
      </div>
    </section>

    <!-- ========================= -->
    <!-- HARDWARE                  -->
    <!-- ========================= -->
    <section id="hardware" class="section">
      <div class="container">
        <header class="section-header style-a">
          <h2>Implementation: Hardware Selection &amp; Integration</h2>
          <p class="muted">
            We explored two drone platforms. The primary challenge was achieving autonomous control access that matched our controller output.
          </p>
        </header>

        <div class="feature-rows">
          <div class="feature">
            <figure class="feature-media">
              <img src="./assets/img/slides/slide_24.png" alt="Slide about Drone 1 JY08 Pro and Wireshark interception attempt" loading="lazy" />
            </figure>
            <div class="feature-body">
              <h3>Drone 1: JY08 Pro (attempt)</h3>
              <p>
                This drone was controlled through Wi-Fi commands sent from a mobile app. We attempted to intercept and replicate command packets
                (WireShark), and considered sending commands via an Android emulator, but the takeoff sequence could not be reliably emulated.
              </p>
            </div>
          </div>

          <div class="feature">
            <figure class="feature-media">
              <img src="./assets/img/slides/slide_25.png" alt="Slide about DJI Tello SDK limitations and command interface" loading="lazy" />
            </figure>
            <div class="feature-body">
              <h3>Drone 2: DJI Tello (final hardware)</h3>
              <p>
                We chose DJI Tello because the official SDK allows autonomous control, but it provides only high-level commands (e.g., ‚Äúmove forward one meter‚Äù),
                not low-level propeller thrust control. We therefore adapted our planner/controller output to the SDK‚Äôs command interface.
              </p>
            </div>
          </div>
        </div>


        <div class="stack">
          <div class="parts-grid">
            <div class="part-card">
              <div class="icon-placeholder">üì∑</div>
              <div>
                <h4>Video Camera Stream</h4>
                <ul class="muted">
                  <li>Laptop connects to the Tello‚Äôs 2.4 GHz 802.11n Wi-Fi AP</li>
                  <li>Enable video with <code>streamon</code></li>
                  <li>Receive the H.264 video stream over UDP (port 11111) and decode frames for vision (e.g., ArUco detection)</li>
                </ul>
              </div>
            </div>
            <div class="part-card">
              <div class="icon-placeholder">üì°</div>
              <div>
                <h4>Command Broadcasting</h4>
                <ul class="muted">
                  <li>Send text-based SDK commands over UDP to 192.168.10.1:8889</li>
                  <li>Start with <code>command</code> to enter SDK mode</li>
                  <li>Drone replies with ok / error (<a href="https://dl-cdn.ryzerobotics.com/downloads/tello/20180910/Tello%20SDK%20Documentation%20EN_1.3.pdf" target="_blank" rel="noopener noreferrer">SDK Documentation</a>)</li>
                </ul>
              </div>
            </div>
          </div>
        </div>

        <details class="details">
          <summary><strong>Adapting the controller to Tello‚Äôs SDK</strong></summary>
          <div class="details-inner">
            <div class="gallery">
              <figure class="media-card">
                <img src="./assets/img/slides/slide_26.png" alt="Adapting our controller workaround slide" loading="lazy" />
                <figcaption>Workaround strategy.</figcaption>
              </figure>
              <figure class="media-card">
                <img src="./assets/img/slides/slide_27.png" alt="Adjusting cost function weights for Tello hardware slide" loading="lazy" />
                <figcaption>Penalize roll/pitch to favor straight translational motion.</figcaption>
              </figure>
              <figure class="media-card">
                <img src="./assets/img/slides/slide_28.png" alt="Adjusted hardware QRP weights plot slide" loading="lazy" />
                <figcaption>Hardware-oriented Q/R/P tuning (example).</figcaption>
              </figure>
            </div>

            <p class="muted small">
              <span class="todo">TODO ‚Äî describe your discretization method: how you convert a continuous trajectory into a sequence of Tello commands.</span>
            </p>
          </div>
        </details>
      </div>
    </section>


    <!-- ========================= -->
    <!-- SOFTWARE                 -->
    <!-- ========================= -->

    <section id="software" class="section gradient">
      <div class="container">
        <header class="section-header style-a">
          <h2>Implementation: Full-Stack Technical Rundown</h2>
          <p class="muted">Full technical walk through of all the parts and how they fit together.</p>
        </header>


        <div class="tab-card inline" id="hardware-overview-card">
          <div class="tab-title" style="font-size:22px;">Hardware Overview</div>
          <div class="tab-panel active">
            <div class="two-col">
              <div class="stack">
                <h3>Hardware</h3>
                <div class="cards-grid" style="grid-template-columns: repeat(1, 1fr); margin-top: 0;">
                  <div class="card">
                    <h3>DJI Tello Drone</h3>
                    <p>A lightweight quadrotor used as the aerial platform. The drone provided:</p>
                    <div class="cards-grid" style="grid-template-columns: repeat(2, 1fr); margin-top: 10px;">
                      <div class="card"><p class="muted">An onboard forward-facing FPV camera</p></div>
                      <div class="card"><p class="muted">Wireless communication over Wi-Fi</p></div>
                      <div class="card"><p class="muted">High-level motion commands (translations and yaw)</p></div>
                      <div class="card"><p class="muted">Internal low-level stabilization (attitude and motor control)</p></div>
                    </div>
                  </div>
                  <div class="card">
                    <h3>Obstacle Course (Rectangular Hoops Made out of PVC Pipes)</h3>
                    <p class="muted">Each obstacle was a rectangular gate with <strong>ArUco tags mounted on its four corners</strong>, allowing reliable visual detection and geometric pose estimation.</p>
                  </div>
                  <div class="card">
                    <h3>Ground Computer (Laptop)</h3>
                    <ul class="muted">
                      <li>Receive the live video stream</li>
                      <li>Run computer vision and state estimation</li>
                      <li>Solve the MPC/LQR optimization problem</li>
                      <li>Send motion commands back to the drone</li>
                    </ul>
                  </div>
                </div>
              </div>
              <div class="stack">
                <h3>Software &amp; Libraries</h3>
                <div class="cards-grid" style="grid-template-columns: 1fr; margin-top: 0;">
                  <div class="card">
                    <h3>DJI Tello SDK</h3>
                    <ul class="muted">
                      <li>Sending flight commands (<code>takeoff</code>, <code>land</code>, translations, yaw)</li>
                      <li>Receiving the FPV video stream over Wi-Fi</li>
                    </ul>
                  </div>
                  <div class="card">
                    <h3>Control Stack</h3>
                    <ul class="muted">
                      <li>OpenCV2 for ArUco detection</li>
                      <li>Casadi Optimization Library</li>
                      <li>C++ IPOPT optimization algorithm (interior point method)</li>
                      <li>MPC controller</li>
                      <li>Custom trajectory post-processing and command generation logic</li>
                    </ul>
                  </div>
                  <div class="card">
                    <h3>Software Architecture and Implementation Details</h3>
                    <p class="muted">The software was structured as a <strong>checkpoint-based autonomy pipeline</strong>, where each obstacle (including takeoff and landing) was treated as a discrete goal state.</p>
                    <p class="muted">The system continuously cycles through the following stages:</p>
                    <ol class="muted">
                      <li>State estimation</li>
                      <li>Checkpoint evaluation</li>
                      <li>Perception (ArUco detection)</li>
                      <li>Trajectory planning (MPC/LQR)</li>
                      <li>Command execution</li>
                      <li>Transition to the next checkpoint</li>
                    </ol>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>

        <div class="tab-card side" id="software-modules-tabs">
          <div class="tab-title" style="font-size:22px;">Key Software Modules</div>
          <div class="tab-inner">
            <div class="tab-list" role="tablist" aria-label="Software modules tabs">
              <button type="button" role="tab" aria-selected="true" data-tab="mod-state">State Estimation</button>
              <button type="button" role="tab" aria-selected="false" data-tab="mod-perception">Perception</button>
              <button type="button" role="tab" aria-selected="false" data-tab="mod-mpc">MPC / LQR</button>
              <button type="button" role="tab" aria-selected="false" data-tab="mod-cost">Cost Function</button>
              <button type="button" role="tab" aria-selected="false" data-tab="mod-trajectory">Trajectory Post-Processing</button>
            </div>
            <div class="tab-panel active" id="tab-mod-state" role="tabpanel">
              <h3>State Estimation</h3>
              <ul class="muted">
                <li>Last known commanded motion</li>
                <li>Camera-based pose estimation relative to the obstacle</li>
                <li>Relative positioning to detected obstacles</li>
                <li>Assumptions about motion execution accuracy</li>
              </ul>
            </div>
            <div class="tab-panel" id="tab-mod-perception" role="tabpanel">
              <h3>Perception: ArUco-Based Obstacle Localization</h3>
              <p class="muted">The FPV video stream was processed using OpenCV</p>
              <p class="muted">Steps:</p>
              <ol class="muted">
                <li>Detect the four ArUco tags on an obstacle</li>
                <li>Infer the 3D pose of each tag relative to the camera</li>
                <li>Compute the <strong>center point of the rectangular gate</strong></li>
              </ol>
              <p class="muted">This center point became the <strong>next checkpoint target</strong> for the controller.</p>
            </div>
            <div class="tab-panel" id="tab-mod-mpc" role="tabpanel">
              <h3>Model Predictive Control with Constrained LQR Cost</h3>
              <p class="muted">Originally in simulation, the controller:</p>
              <ul class="muted">
                <li>Output continuous thrust and torque commands</li>
                <li>Used a <strong>short receding horizon</strong> for real-time control</li>
              </ul>
              <h4>Hardware-Driven Modifications (SDK limits)</h4>
              <ul class="muted">
                <li>Translational commands ‚â• <strong>10 cm</strong></li>
                <li>Rotational commands ‚â• <strong>10¬∞</strong></li>
                <li>Commands executed slowly with pauses, stabilized onboard</li>
              </ul>
              <p class="muted">As a result, the MPC horizon was <strong>lengthened</strong>, allowed more compute time, and issued fewer commands to reduce drift and uncertainty.</p>
            </div>
            <div class="tab-panel" id="tab-mod-cost" role="tabpanel">
              <h3>Cost Function Adjustments</h3>
              <p class="muted">To ensure feasible real-world flight:</p>
              <ul class="muted">
                <li><strong>Roll and pitch states</strong> heavily penalized</li>
                <li><strong>Torques about x/y</strong> heavily penalized</li>
              </ul>
              <p class="muted">Encouraged:</p>
              <ul class="muted">
                <li>Straight-line translational motion</li>
                <li>Yaw-based reorientation</li>
                <li>Minimal aggressive maneuvering</li>
              </ul>
            </div>
            <div class="tab-panel" id="tab-mod-trajectory" role="tabpanel">
              <h3>Trajectory Post-Processing</h3>
              <p class="muted">Instead of directly applying control inputs:</p>
              <ol class="muted">
                <li>Compute the optimal MPC trajectory over the horizon</li>
                <li>Decompose into <strong>three sequential commands</strong>:
                  <ul>
                    <li>Vertical translation</li>
                    <li>Yaw rotation</li>
                    <li>Forward/backward translation</li>
                  </ul>
                </li>
                <li>Discretize each to satisfy SDK constraints</li>
                <li>Send commands wirelessly to the drone</li>
              </ol>
            </div>
          </div>
        </div>

        <!-- Dynamics and Control Section -->
        <div class="two-col" style="margin-top: 48px;">
          <div class="stack">
            <h3>Quadrotor Dynamics Model</h3>
            <p class="muted">
              The quadrotor dynamics were derived from first principles, modeling forces and torques acting on the rigid body:
            </p>
            
            <h4>Forces</h4>
            <p class="muted">The translational acceleration is governed by:</p>
            <div class="math-block">
              <img src="./assets/img/slides/slide_06.png" alt="Dynamics forces equation" loading="lazy" style="max-width: 100%; border-radius: 8px;" />
            </div>
            <p class="muted small">
              Where the total thrust force <code>f<sub>total</sub></code> acts in the body frame and gravity acts downward in the world frame. 
              The rotation matrix <code>R<sub>ab</sub>(œÜ, Œ∏, œà)</code> transforms body forces to the world frame.
            </p>

            <h4>Linearization</h4>
            <p class="muted">
              For control design, we linearized the model around hover by applying <strong>small angle approximations</strong>:
            </p>
            <div class="math-block">
              <img src="./assets/img/slides/slide_07.png" alt="Linearization with small angle approximations" loading="lazy" style="max-width: 100%; border-radius: 8px;" />
            </div>
            <div class="math-block">
              <img src="./assets/img/slides/slide_08.png" alt="Angular dynamics linearization" loading="lazy" style="max-width: 100%; border-radius: 8px;" />
            </div>
            <p class="muted small">
              This simplifies the rotation matrix to a first-order approximation and decouples translational motion from rotational dynamics 
              at small attitudes.
            </p>

            <h4>Angular Dynamics</h4>
            <p class="muted">
              Continuing the linearization process, we apply additional small angle approximations to the body rate transformations:
            </p>
            <div class="math-block">
              <img src="./assets/img/slides/slide_09.png" alt="More small angle approximations for angular rates" loading="lazy" style="max-width: 100%; border-radius: 8px;" />
            </div>
            <p class="muted small">
              The angular acceleration depends on applied torques and the quadrotor's moments of inertia. By assuming small angles, 
              the complex nonlinear coupling terms simplify to a linear relationship between angular rates and applied torques, 
              making the system tractable for real-time optimal control.
            </p>
            <p class="muted small">
              This further simplifies the kinematic relationships between body-frame angular velocities (p, q, r) and the Euler angle rates (œÜÃá, Œ∏Ãá, œàÃá), 
              reducing the transformation to an identity-like mapping. This allows us to directly integrate angular accelerations into Euler angle dynamics 
              in the final state-space representation.
            </p>

            <h4>Fully Linearized State-Space Model</h4>
            <p class="muted">
              The complete linearized system takes the form <code>·∫ã = Ax + Bu</code> with 12 states 
              (position, orientation, and their derivatives) and 4 control inputs (total thrust and three torques):
            </p>
            <div class="math-block">
              <img src="./assets/img/slides/slide_10.png" alt="Fully linearized model" loading="lazy" style="max-width: 100%; border-radius: 8px;" />
            </div>
          </div>

          <div class="stack">
            <h3>Mixer Matrix</h3>
            <p class="muted">
              In simulation, individual propeller thrusts are mapped to total thrust and body torques using a <strong>mixer matrix</strong>:
            </p>
            <div class="math-block">
              <img src="./assets/img/slides/slide_11.png" alt="Mixer matrix equations" loading="lazy" style="max-width: 100%; border-radius: 8px;" />
            </div>
            <p class="muted small">
              This allows the controller to compute desired forces and torques, which are then inverted to find individual motor commands. 
              On hardware, this low-level control is replaced by SDK position commands.
            </p>

            <h3>Receding-Horizon LQR Optimization</h3>
            <p class="muted">
              The Model Predictive Controller solves a finite-horizon optimal control problem at each time step:
            </p>
            <div class="math-block">
              <img src="./assets/img/slides/slide_12.png" alt="LQR optimization problem" loading="lazy" style="max-width: 100%; border-radius: 8px;" />
            </div>
            <p class="muted">
              <strong>Key components:</strong>
            </p>
            <ul class="muted">
              <li><strong>Cost function:</strong> Penalizes state deviations (via <code>Q</code>) and control effort (via <code>R</code>), 
                with a terminal cost <code>P</code></li>
              <li><strong>Constraints:</strong> System dynamics <code>x<sub>k+1</sub> = Ax<sub>k</sub> + Bu<sub>k</sub></code></li>
              <li><strong>Control limits:</strong> <code>u<sub>min</sub> ‚â§ u<sub>k</sub> ‚â§ u<sub>max</sub></code> to respect actuator saturation</li>
              <li><strong>Receding horizon:</strong> Only the first control action is applied; the optimization is re-solved at the next time step 
                with updated measurements</li>
            </ul>
            <p class="muted small">
              This approach provides both optimality and reactivity, allowing the controller to adapt to changing conditions and perception updates 
              in real time.
            </p>
          </div>
        </div>

      </div>
    </section>

    <!-- ========================= -->
    <!-- ========================= -->
    <!-- OPERATION                  -->
    <!-- ========================= -->
    <section id="operation" class="section alt">
      <div class="container">
        <header class="section-header style-a">
          <h2>Complete System Operation</h2>
          <p class="muted">Step-by-Step Autonomous Pipeline. Hover over nodes for details.</p>
        </header>
        <div class="flow-wrapper">
          <div class="flowchart" id="flowchart">
            <svg class="connections" id="connections" aria-hidden="true">
              <defs>
                <marker id="arrow" viewBox="0 0 10 10" refX="9" refY="5" markerWidth="8" markerHeight="8" orient="auto-start-reverse">
                  <path d="M 0 0 L 10 5 L 0 10 z" fill="rgba(255,255,255,0.45)" />
                </marker>
              </defs>
            </svg>
            <div class="nodes" id="nodes">
              <button class="node" data-step="1"><strong>1. Takeoff</strong><span>Init</span></button>
              <button class="node" data-step="2"><strong>2. Checkpoint 1</strong><span>Obstacle 1</span></button>
              <button class="node" data-step="3"><strong>3. Planning</strong><span>MPC / LQR</span></button>
              <button class="node" data-step="4"><strong>4. Execution</strong><span>Commands</span></button>
              <button class="node" data-step="5"><strong>5. Completion</strong><span>Checkpoint</span></button>
              <button class="node" data-step="6"><strong>6. Repeat</strong><span>Cycle</span></button>
              <button class="node" data-step="7"><strong>7. Landing</strong><span>Final</span></button>
            </div>
            <div class="popup" id="popup" role="tooltip" aria-hidden="true"></div>
          </div>
        </div>
      </div>
    </section>

    <!-- ========================= -->
    <!-- DISCUSSION                -->
    <!-- ========================= -->
    <section id="discussion" class="section">
      <div class="container">
        <header class="section-header style-a tight">
          <h2>Summary</h2>
        </header>

        <p class="muted summary-text">This project demonstrates how <strong>advanced optimal control techniques</strong> (MPC with LQR cost) can be successfully adapted to <strong>real-world hardware constraints</strong>. By restructuring the controller to output long-horizon trajectories and discrete high-level commands, the system achieved reliable autonomous flight through a sequence of obstacles despite limited sensing, actuation, and telemetry.</p>
        
        <p class="muted"><strong>Results & Live Drone Demo</strong></p>

        <div class="video-grid">
          <div class="video-card">
            <div class="video-embed" aria-label="Demo video placeholder">
              <video controls playsinline preload="metadata" aria-label="Drone gate navigation demo">
                <source src="./assets/videos/livedemo.mp4" type="video/mp4" />
                Your browser does not support the video tag.
              </video>
            </div>
            <p class="muted small">
              The system successfully demonstrated autonomous flight from takeoff to landing. It was able to detect gates within its field of view, plan and execute trajectories to pass through each gate, re-localize subsequent gates, and repeat the process without human intervention.
            </p>
          </div>
        </div>
        <p class="muted summary-text conclusion-title"><strong>Conclusion</strong></p>
        <div class="stack">
          <p class="muted summary-text"><strong>(a) Results and Design Criteria</strong> The final system met the primary design criteria by achieving fully autonomous operation, including takeoff, gate detection, trajectory planning, gate traversal, and landing. The modular pipeline operated in real time and performed reliably in both simulation and on hardware, demonstrating stable closed-loop control and successful perception-to-control integration.</p>
          <p class="muted summary-text"><strong>(b) Difficulties Encountered</strong> A major challenge arose during the transition from simulation to hardware. While the MuJoCo simulation was designed around low-level propeller thrust control, the DJI Tello does not provide access to individual propeller commands through its SDK. This mismatch required a significant redesign of the control interface late in the project.</p>
          <p class="muted summary-text"><strong>(c) Flaws, Hacks, and Future Improvements</strong> To address this limitation, the controller was adapted to operate using the Tello SDK‚Äôs high-level position and yaw commands rather than direct motor inputs. While effective, this workaround reduced control authority and strayed from the optimal trajectory. With additional time, a drone platform offering low-level actuation access would be used to fully leverage the original control design. Additionally, replacing ArUco-based perception with a learned vision model would improve robustness and generality when operating with new or unstructured obstacles.</p>
        </div>
      </div>
    </section>

    <!-- ========================= -->
    <!-- TEAM                      -->
    <!-- ========================= -->
    <section id="team" class="section alt">
      <div class="container">
        <header class="section-header style-a">
          <h2>Team</h2>
          <p class="muted">
            Alejandro Municio ¬∑ Ben Finch ¬∑ Michael Howo ¬∑ Rohin Shanker
          </p>
        </header>

        <div class="cards-grid">
          <div class="card">
            <h3>Alejandro Municio</h3>
            <p class="muted"><a href="https://www.linkedin.com/in/alejandro-municio-aerospace/" target="_blank" rel="noreferrer"><svg class="icon-linkedin" viewBox="0 0 448 512" aria-hidden="true" focusable="false"><path d="M100.28 448H7.4V148.9h92.88zm-46.44-339C24 109 0 85 0 54.9A54.9 54.9 0 0 1 54.13 0a54.88 54.88 0 1 1-.29 109zm394.16 339h-92.68V302.4c0-34.7-12.45-58.4-43.55-58.4-23.74 0-37.88 16-44.1 31.4-2.26 5.5-2.82 13.1-2.82 20.8V448h-92.78s1.22-251.1 0-277.1h92.78v39.3c-.18.3-.43.6-.6.9h.6v-.9c12.34-19 34.35-46.1 83.6-46.1 61 0 106.68 39.9 106.68 125.5z"/></svg>LinkedIn</a></p>
            <p class="muted"><strong>Bio:</strong> Alejandro is a Master‚Äôs student at UC Berkeley, his interests are controls and autonomous aerial vehicles. In his free time he likes to swim and scuba dive.</p>
            <p class="muted"><strong>Contributions:</strong>Model Predictive Controls and Optimization</p>
          </div>
          <div class="card">
            <h3>Ben Finch</h3>
            <p class="muted"><a href="https://www.linkedin.com/in/ben--finch/" target="_blank" rel="noreferrer"><svg class="icon-linkedin" viewBox="0 0 448 512" aria-hidden="true" focusable="false"><path d="M100.28 448H7.4V148.9h92.88zm-46.44-339C24 109 0 85 0 54.9A54.9 54.9 0 0 1 54.13 0a54.88 54.88 0 1 1-.29 109zm394.16 339h-92.68V302.4c0-34.7-12.45-58.4-43.55-58.4-23.74 0-37.88 16-44.1 31.4-2.26 5.5-2.82 13.1-2.82 20.8V448h-92.78s1.22-251.1 0-277.1h92.78v39.3c-.18.3-.43.6-.6.9h.6v-.9c12.34-19 34.35-46.1 83.6-46.1 61 0 106.68 39.9 106.68 125.5z"/></svg>LinkedIn</a></p>
            <p class="muted"><strong>Bio:</strong> Ben is a Master‚Äôs student at UC Berkeley, specializing in robotics. His interests are fluids, powertrains, and robotics.</p>
            <p class="muted"><strong>Contributions:</strong> Computer Vision and Simulation</p>
          </div>
          <div class="card">
            <h3>Michael Howo</h3>
            <p class="muted"><a href="https://www.linkedin.com/in/michaelhowo/" target="_blank" rel="noreferrer"><svg class="icon-linkedin" viewBox="0 0 448 512" aria-hidden="true" focusable="false"><path d="M100.28 448H7.4V148.9h92.88zm-46.44-339C24 109 0 85 0 54.9A54.9 54.9 0 0 1 54.13 0a54.88 54.88 0 1 1-.29 109zm394.16 339h-92.68V302.4c0-34.7-12.45-58.4-43.55-58.4-23.74 0-37.88 16-44.1 31.4-2.26 5.5-2.82 13.1-2.82 20.8V448h-92.78s1.22-251.1 0-277.1h92.78v39.3c-.18.3-.43.6-.6.9h.6v-.9c12.34-19 34.35-46.1 83.6-46.1 61 0 106.68 39.9 106.68 125.5z"/></svg>LinkedIn</a></p>
            <p class="muted"><strong>Bio:</strong>Michael is a Masters Student at UC Berkeley, majoring in Mechanical Engineering with a specialization in robotics. </p>
            <p class="muted"><strong>Contributions:</strong>Hardware Integration</p>
          </div>
          <div class="card">
            <h3>Rohin Shanker</h3>
            <p class="muted"><a href="https://www.linkedin.com/in/rohin-shanker/" target="_blank" rel="noreferrer"><svg class="icon-linkedin" viewBox="0 0 448 512" aria-hidden="true" focusable="false"><path d="M100.28 448H7.4V148.9h92.88zm-46.44-339C24 109 0 85 0 54.9A54.9 54.9 0 0 1 54.13 0a54.88 54.88 0 1 1-.29 109zm394.16 339h-92.68V302.4c0-34.7-12.45-58.4-43.55-58.4-23.74 0-37.88 16-44.1 31.4-2.26 5.5-2.82 13.1-2.82 20.8V448h-92.78s1.22-251.1 0-277.1h92.78v39.3c-.18.3-.43.6-.6.9h.6v-.9c12.34-19 34.35-46.1 83.6-46.1 61 0 106.68 39.9 106.68 125.5z"/></svg>LinkedIn</a></p>
            <p class="muted"><strong>Bio:</strong> Rohin is an undergraduate at UC Berkeley, majoring in EECS and Bioengineering with a certificate in entrepreneurship technology.</p>
            <p class="muted"><strong>Contributions:</strong> Website, Integration, Slides</p>
          </div>
        </div>

        
      </div>
    </section>

    <footer class="site-footer">
      <div class="container footer-inner">
        <p class="muted small">
          Team 44 ¬∑ EECS/ME C106A/206A (Fall 2025).
        </p>
        <a class="back-to-top" href="#top">Back to top</a>
      </div>
    </footer>
  </main>

  <div id="lightbox" aria-hidden="true">
    <button id="lightbox-close" class="lightbox-close" aria-label="Close image">√ó</button>
    <img id="lightbox-img" alt="" />
  </div>

  <script id="flowchart-script">
    const steps = [
      {
        id: 1,
        title: "Takeoff and Initialization",
        listType: "ol",
        items: [
          "The drone receives the SDK `takeoff` command",
          "It ascends to a preset altitude",
          { text: "This altitude was chosen to ensure:", subitems: ["Clear line-of-sight", "Reliable detection of the first obstacle"], subListType: "ul" }
        ]
      },
      {
        id: 2,
        title: "First Checkpoint ‚Äì Obstacle 1",
        listType: "ol",
        items: [
          "The drone streams camera data to the ground computer",
          "ArUco tags on Obstacle 1 are detected",
          "The obstacle‚Äôs center point is estimated",
          "This center becomes the **current checkpoint**"
        ]
      },
      {
        id: 3,
        title: "Trajectory Planning",
        listType: "ol",
        items: [
          "The MPC controller computes an optimal trajectory",
          { text: "A long receding horizon is used to:", subitems: ["Reduce the number of corrective actions", "Minimize accumulated position error"], subListType: "ul" },
          "The trajectory is optimized using a constrained LQR cost"
        ]
      },
      {
        id: 4,
        title: "Command Execution",
        listType: "ol",
        items: [
          { text: "The trajectory is converted into:", subitems: ["Vertical motion", "Yaw rotation", "Forward/backward motion"], subListType: "ul" },
          "Commands are sent via the SDK",
          "The drone executes them with internal stabilization"
        ]
      },
      {
        id: 5,
        title: "Checkpoint Completion",
        listType: "ul",
        items: [
          { text: "Once the drone is within a predefined distance of the obstacle center:", subitems: ["The checkpoint is marked as complete", "The next obstacle becomes the active target"], subListType: "ul" }
        ]
      },
      {
        id: 6,
        title: "Repeating the Cycle",
        listType: "ul",
        items: [
          { text: "Steps 2‚Äì5 repeat for:", subitems: ["Obstacle 2", "Obstacle 3", "‚Ä¶", "Final obstacle"], subListType: "ul" },
          "ArUco tags for upcoming obstacles are often detected **mid-flight**, reducing transition delay"
        ]
      },
      {
        id: 7,
        title: "Final Landing Sequence",
        listType: "ol",
        items: [
          { text: "After clearing the final obstacle:", subitems: ["The system switches to the landing checkpoint"], subListType: "ul" },
          "The SDK `land` command is issued",
          "The mission ends"
        ]
      }
    ];

    const flowchart = document.getElementById("flowchart");
    const popup = document.getElementById("popup");
    const nodes = Array.from(document.querySelectorAll(".node"));
    let activeId = null;
    let hideTimeout = null;

    function parseInline(text){
      return text
        .replace(/`([^`]+)`/g, "<code>$1</code>")
        .replace(/\*\*([^*]+)\*\*/g, "<strong>$1</strong>");
    }

    function renderList(listType, items){
      const list = document.createElement(listType);
      items.forEach((item) => {
        const li = document.createElement("li");
        if (typeof item === "string") {
          li.innerHTML = parseInline(item);
        } else {
          li.innerHTML = parseInline(item.text);
          if (item.subitems && item.subitems.length) {
            const sub = document.createElement(item.subListType || "ul");
            item.subitems.forEach((subitem) => {
              const subLi = document.createElement("li");
              subLi.innerHTML = parseInline(subitem);
              sub.appendChild(subLi);
            });
            li.appendChild(sub);
          }
        }
        list.appendChild(li);
      });
      return list;
    }

    function showPopup(stepId, trigger){
      const step = steps.find((s) => s.id === stepId);
      if (!step) return;
      activeId = stepId;
      nodes.forEach((n) => n.classList.toggle("active", Number(n.dataset.step) === stepId));

      popup.innerHTML = "";
      const header = document.createElement("div");
      header.className = "header";
      header.innerHTML = `<span class="badge">Step ${step.id}</span><h3>${step.title}</h3>`;
      popup.appendChild(header);
      popup.appendChild(renderList(step.listType, step.items));
      popup.setAttribute("aria-hidden", "false");
      popup.classList.add("visible");

      positionPopup(trigger);
      trigger.setAttribute("aria-describedby", "popup");
    }

    function hidePopup(){
      activeId = null;
      popup.classList.remove("visible");
      popup.setAttribute("aria-hidden", "true");
      nodes.forEach((n) => n.classList.remove("active"));
      nodes.forEach((n) => n.removeAttribute("aria-describedby"));
    }

    function scheduleHide(){
      clearTimeout(hideTimeout);
      hideTimeout = setTimeout(() => {
        if (!popup.matches(":hover") && !nodes.some((n) => n.matches(":hover"))) {
          hidePopup();
        }
      }, 120);
    }

    function positionPopup(trigger){
      const containerRect = flowchart.getBoundingClientRect();
      const triggerRect = trigger.getBoundingClientRect();
      const popupRect = popup.getBoundingClientRect();

      let x = triggerRect.left - containerRect.left - popupRect.width - 12;
      let y = triggerRect.top - containerRect.top + (triggerRect.height / 2) - (popupRect.height / 2);

      const margin = 12;
      if (x < margin) {
        x = triggerRect.right - containerRect.left + 12;
      }
      if (x + popupRect.width > containerRect.width - margin) {
        x = containerRect.width - popupRect.width - margin;
      }
      if (x < margin) x = margin;
      if (y < margin) y = margin;
      if (y + popupRect.height > containerRect.height - margin) {
        y = containerRect.height - popupRect.height - margin;
      }

      popup.style.left = `${x}px`;
      popup.style.top = `${y}px`;
    }

    nodes.forEach((node) => {
      const stepId = Number(node.dataset.step);
      node.addEventListener("pointerenter", () => {
        clearTimeout(hideTimeout);
        showPopup(stepId, node);
      });
      node.addEventListener("pointerleave", scheduleHide);
      node.addEventListener("focus", () => showPopup(stepId, node));
      node.addEventListener("blur", scheduleHide);
      node.addEventListener("click", (e) => {
        e.stopPropagation();
        if (activeId === stepId) {
          hidePopup();
        } else {
          showPopup(stepId, node);
        }
      });
      node.addEventListener("keydown", (e) => {
        if (e.key === "Enter" || e.key === " ") {
          e.preventDefault();
          node.click();
        }
      });
    });

    popup.addEventListener("pointerenter", () => clearTimeout(hideTimeout));
    popup.addEventListener("pointerleave", scheduleHide);

    document.addEventListener("click", (e) => {
      if (!popup.contains(e.target)) hidePopup();
    });
    document.addEventListener("keydown", (e) => {
      if (e.key === "Escape") hidePopup();
    });

    const connections = document.getElementById("connections");

    function nodeCenter(node){
      const rect = node.getBoundingClientRect();
      const containerRect = flowchart.getBoundingClientRect();
      return {
        x: rect.left - containerRect.left + rect.width / 2,
        y: rect.top - containerRect.top + rect.height / 2,
        right: rect.right - containerRect.left,
        left: rect.left - containerRect.left,
        top: rect.top - containerRect.top,
        bottom: rect.bottom - containerRect.top,
        width: rect.width,
        height: rect.height
      };
    }

    function pathBetween(a, b){
      const dx = b.x - a.x;
      const dy = b.y - a.y;
      const c1x = a.x + dx * 0.35;
      const c1y = a.y;
      const c2x = a.x + dx * 0.65;
      const c2y = b.y;
      return `M ${a.x} ${a.y} C ${c1x} ${c1y}, ${c2x} ${c2y}, ${b.x} ${b.y}`;
    }

    function drawConnections(){
      const containerRect = flowchart.getBoundingClientRect();
      connections.setAttribute("viewBox", `0 0 ${containerRect.width} ${containerRect.height}`);
      connections.innerHTML = '<defs><marker id="arrow" viewBox="0 0 10 10" refX="9" refY="5" markerWidth="8" markerHeight="8" orient="auto-start-reverse"><path d="M 0 0 L 10 5 L 0 10 z" fill="rgba(255,255,255,0.45)" /></marker></defs>';

      const get = (id) => nodeCenter(nodes[id - 1]);
      const step1 = get(1);
      const step2 = get(2);
      const step3 = get(3);
      const step4 = get(4);
      const step5 = get(5);
      const step6 = get(6);
      const step7 = get(7);

      const paths = [];
      paths.push(pathBetween({ x: step1.right, y: step1.y }, { x: step2.left, y: step2.y }));
      paths.push(pathBetween({ x: step2.right, y: step2.y }, { x: step3.left, y: step3.y }));
      paths.push(pathBetween({ x: step3.right, y: step3.y }, { x: step4.left, y: step4.y }));
      paths.push(pathBetween({ x: step4.right, y: step4.y }, { x: step5.left, y: step5.y }));
      paths.push(pathBetween({ x: step5.right, y: step5.y }, { x: step6.left, y: step6.y }));
      paths.push(pathBetween({ x: step6.x, y: step6.bottom }, { x: step7.x, y: step7.top }));

      const loopStart = { x: step6.right, y: step6.y };
      const loopEnd = { x: step2.top + step2.width / 2, y: step2.top - 10 };
      const loopPath = `M ${loopStart.x} ${loopStart.y}
        C ${loopStart.x + 120} ${loopStart.y - 80}, ${loopEnd.x + 120} ${loopEnd.y - 80}, ${loopEnd.x} ${loopEnd.y}`;
      paths.push(loopPath);

      paths.forEach((d) => {
        const path = document.createElementNS("http://www.w3.org/2000/svg", "path");
        path.setAttribute("d", d);
        path.setAttribute("marker-end", "url(#arrow)");
        connections.appendChild(path);
      });
    }

    const ro = new ResizeObserver(() => drawConnections());
    ro.observe(flowchart);
    window.addEventListener("resize", drawConnections);
    window.addEventListener("load", drawConnections);
    if (document.fonts && document.fonts.ready) {
      document.fonts.ready.then(drawConnections);
    }
  </script>
  <script src="./assets/js/main.js"></script>
</body>
</html>
